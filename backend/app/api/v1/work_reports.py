# backend/app/api/v1/work_reports.py
from fastapi import APIRouter, Depends, HTTPException, Query, UploadFile, File, status
from typing import Optional, List, Dict, Any
from datetime import date, datetime, timedelta
import logging
import pandas as pd
import io
import re
import os

from ...schemas.work_report import (
    WorkReportResponse, 
    WorkReportSearchRequest,
    WorkReportCreate,
    WorkReportUpdate,
    EmployeeCreate,
    ProjectCreate,
    DepartmentCreate
)
from ...repository.work_report_repo import WorkReportRepository
from ...db.mongo import get_db

router = APIRouter(prefix="/work-reports", tags=["æŠ¥å·¥ç®¡ç†"])
logger = logging.getLogger(__name__)

@router.get("/search")
async def search_work_reports(
    keyword: Optional[str] = Query(None, description="æœç´¢å…³é”®å­—"),
    employee_name: Optional[str] = Query(None, description="å‘˜å·¥å§“å"),
    project_name: Optional[str] = Query(None, description="é¡¹ç›®åç§°"),
    department_name: Optional[str] = Query(None, description="éƒ¨é—¨åç§°"),
    start_date: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    end_date: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    status: Optional[str] = Query(None, description="çŠ¶æ€"),
    page: int = Query(1, ge=1, description="é¡µç "),
    size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    db = Depends(get_db)
):
    """æ™ºèƒ½æœç´¢æŠ¥å·¥è®°å½•"""
    try:
        repo = WorkReportRepository(db)
        result = await repo.search_work_reports(
            keyword=keyword,
            employee_name=employee_name,
            project_name=project_name,
            department_name=department_name,
            start_date=start_date,
            end_date=end_date,
            status=status,
            page=page,
            size=size
        )
        return {
            "success": True,
            "data": result
        }
    except Exception as e:
        logger.error(f"æœç´¢æŠ¥å·¥è®°å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/import")
async def import_excel_data(
    data: List[Dict[str, Any]],
    db = Depends(get_db)
):
    """å¯¼å…¥Excelæ•°æ®"""
    try:
        repo = WorkReportRepository(db)
        count = await repo.import_excel_data(data)
        return {
            "success": True,
            "message": f"æˆåŠŸå¯¼å…¥ {count} æ¡è®°å½•",
            "count": count
        }
    except Exception as e:
        logger.error(f"å¯¼å…¥Excelæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/upload-excel")
async def upload_excel_file(
    file: UploadFile = File(...),
    db = Depends(get_db)
):
    """ä¸Šä¼ Excelæ–‡ä»¶å¹¶è§£æå¯¼å…¥"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.filename.endswith(('.xlsx', '.xls')):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒExcelæ–‡ä»¶æ ¼å¼")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # ä½¿ç”¨pandasè¯»å–Excel
        try:
            df = pd.read_excel(io.BytesIO(content))
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Excelæ–‡ä»¶è§£æå¤±è´¥: {str(e)}")
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data = df.to_dict('records')
        
        # æ¸…ç†ç©ºå€¼
        cleaned_data = []
        for item in data:
            cleaned_item = {k: v for k, v in item.items() if pd.notna(v)}
            if cleaned_item:  # åªæ·»åŠ éç©ºè®°å½•
                cleaned_data.append(cleaned_item)
        
        # å¯¼å…¥æ•°æ®
        repo = WorkReportRepository(db)
        count = await repo.import_excel_data(cleaned_data)
        
        return {
            "success": True,
            "message": f"æˆåŠŸå¯¼å…¥ {count} æ¡è®°å½•",
            "count": count,
            "filename": file.filename
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸Šä¼ Excelæ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/statistics")
async def get_statistics(db = Depends(get_db)):
    """è·å–æŠ¥å·¥ç»Ÿè®¡ä¿¡æ¯"""
    try:
        repo = WorkReportRepository(db)
        stats = await repo.get_work_report_statistics()
        return {
            "success": True,
            "data": stats
        }
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/export")
async def export_data(
    keyword: Optional[str] = None,
    start_date: Optional[date] = None,
    end_date: Optional[date] = None,
    db = Depends(get_db)
):
    """å¯¼å‡ºæ•°æ®"""
    try:
        repo = WorkReportRepository(db)
        result = await repo.search_work_reports(
            keyword=keyword,
            start_date=start_date,
            end_date=end_date,
            page=1,
            size=10000  # å¯¼å‡ºæ‰€æœ‰æ•°æ®
        )
        return {
            "success": True,
            "data": result["data"]
        }
    except Exception as e:
        logger.error(f"å¯¼å‡ºæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/", response_model=Dict[str, Any])
async def create_work_report(
    work_report: WorkReportCreate,
    db = Depends(get_db)
):
    """åˆ›å»ºæŠ¥å·¥è®°å½•"""
    try:
        repo = WorkReportRepository(db)
        work_report_data = work_report.dict()
        report_id = await repo.create_work_report(work_report_data)
        
        return {
            "success": True,
            "message": "æŠ¥å·¥è®°å½•åˆ›å»ºæˆåŠŸ",
            "id": report_id
        }
    except Exception as e:
        logger.error(f"åˆ›å»ºæŠ¥å·¥è®°å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/{report_id}")
async def get_work_report(
    report_id: str,
    db = Depends(get_db)
):
    """è·å–æŠ¥å·¥è®°å½•è¯¦æƒ…"""
    try:
        repo = WorkReportRepository(db)
        result = await repo.get_work_report_by_id(report_id)
        
        if not result:
            raise HTTPException(status_code=404, detail="æŠ¥å·¥è®°å½•ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "data": result
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æŠ¥å·¥è®°å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.put("/{report_id}")
async def update_work_report(
    report_id: str,
    work_report: WorkReportUpdate,
    db = Depends(get_db)
):
    """æ›´æ–°æŠ¥å·¥è®°å½•"""
    try:
        repo = WorkReportRepository(db)
        update_data = work_report.dict(exclude_unset=True)
        success = await repo.update_work_report(report_id, update_data)
        
        if not success:
            raise HTTPException(status_code=404, detail="æŠ¥å·¥è®°å½•ä¸å­˜åœ¨æˆ–æ›´æ–°å¤±è´¥")
        
        return {
            "success": True,
            "message": "æŠ¥å·¥è®°å½•æ›´æ–°æˆåŠŸ"
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°æŠ¥å·¥è®°å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/{report_id}")
async def delete_work_report(
    report_id: str,
    db = Depends(get_db)
):
    """åˆ é™¤æŠ¥å·¥è®°å½•"""
    try:
        repo = WorkReportRepository(db)
        success = await repo.delete_work_report(report_id)
        
        if not success:
            raise HTTPException(status_code=404, detail="æŠ¥å·¥è®°å½•ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "message": "æŠ¥å·¥è®°å½•åˆ é™¤æˆåŠŸ"
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤æŠ¥å·¥è®°å½•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# å‘˜å·¥ç®¡ç†æ¥å£
@router.post("/employees")
async def create_employee(
    employee: EmployeeCreate,
    db = Depends(get_db)
):
    """åˆ›å»ºå‘˜å·¥ä¿¡æ¯"""
    try:
        repo = WorkReportRepository(db)
        employee_data = employee.dict()
        employee_id = await repo.create_employee(employee_data)
        
        return {
            "success": True,
            "message": "å‘˜å·¥ä¿¡æ¯åˆ›å»ºæˆåŠŸ",
            "id": employee_id
        }
    except Exception as e:
        logger.error(f"åˆ›å»ºå‘˜å·¥ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# é¡¹ç›®ç®¡ç†æ¥å£
@router.post("/projects")
async def create_project(
    project: ProjectCreate,
    db = Depends(get_db)
):
    """åˆ›å»ºé¡¹ç›®ä¿¡æ¯"""
    try:
        repo = WorkReportRepository(db)
        project_data = project.dict()
        project_id = await repo.create_project(project_data)
        
        return {
            "success": True,
            "message": "é¡¹ç›®ä¿¡æ¯åˆ›å»ºæˆåŠŸ",
            "id": project_id
        }
    except Exception as e:
        logger.error(f"åˆ›å»ºé¡¹ç›®ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# éƒ¨é—¨ç®¡ç†æ¥å£
@router.post("/departments")
async def create_department(
    department: DepartmentCreate,
    db = Depends(get_db)
):
    """åˆ›å»ºéƒ¨é—¨ä¿¡æ¯"""
    try:
        repo = WorkReportRepository(db)
        department_data = department.dict()
        department_id = await repo.create_department(department_data)
        
        return {
            "success": True,
            "message": "éƒ¨é—¨ä¿¡æ¯åˆ›å»ºæˆåŠŸ",
            "id": department_id
        }
    except Exception as e:
        logger.error(f"åˆ›å»ºéƒ¨é—¨ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# === AIå¯¹è¯å¼æŸ¥è¯¢æ¥å£ ===
@router.post("/ai-query")
async def ai_query(
    payload: Dict[str, Any]
):
    """
    å¯¹è¯å¼æ–‡æœ¬æŸ¥è¯¢æŠ¥å·¥ï¼š
    - è¾“å…¥è‡ªç„¶è¯­è¨€ï¼Œå¦‚ï¼š"æŸ¥è¯¢AIæ™ºèƒ½åŠ©æ‰‹é¡¹ç›®çš„æŠ¥å·¥æƒ…å†µ"ã€"æŸ¥è¯¢ç‹äº”9æœˆçš„æŠ¥å·¥"
    - è¾“å‡ºæ£€ç´¢å‘½ä¸­çš„æŠ¥å·¥è¡¨æ ¼æ•°æ®
    """
    try:
        text = str(payload.get("query", "")).strip()
        if not text:
            raise HTTPException(status_code=400, detail="queryä¸èƒ½ä¸ºç©º")

        # è§„åˆ™å¼è½»é‡è§£æï¼šæå–å¯èƒ½çš„å‘˜å·¥å/é¡¹ç›®å/æ—¥æœŸèŒƒå›´
        employee_name = None
        project_name = None
        keyword = None
        start_date = None
        end_date = None
        
        # æ·»åŠ è¯¦ç»†è°ƒè¯•æ—¥å¿—
        print("=" * 50)
        print(f"ğŸ” AIæŸ¥è¯¢è¯·æ±‚å¼€å§‹")
        print(f"ğŸ“ åŸå§‹æŸ¥è¯¢æ–‡æœ¬: '{text}'")
        print(f"ğŸ“¦ è¯·æ±‚å‚æ•°: {payload}")
        logger.info("=" * 50)
        logger.info(f"ğŸ” AIæŸ¥è¯¢è¯·æ±‚å¼€å§‹")
        logger.info(f"ğŸ“ åŸå§‹æŸ¥è¯¢æ–‡æœ¬: '{text}'")
        logger.info(f"ğŸ“¦ è¯·æ±‚å‚æ•°: {payload}")

        # æå–é¡¹ç›®åç§° - æ”¹è¿›çš„åŒ¹é…é€»è¾‘
        # 1. å…ˆå°è¯•åŒ¹é… "XXXé¡¹ç›®" æ ¼å¼ï¼ˆä¼˜å…ˆåŒ¹é…å­—æ¯é¡¹ç›®åï¼‰
        m = re.search(r"([A-Za-z]{2,})é¡¹ç›®", text)
        if m:
            project_name = m.group(1)
        else:
            # 2. å†å°è¯•åŒ¹é…ä¸­æ–‡é¡¹ç›®å
            m = re.search(r"([\u4e00-\u9fa5]{2,})é¡¹ç›®", text)
            if m:
                project_name = m.group(1)
            else:
                # 3. æœ€åå°è¯•åŒ¹é… "é¡¹ç›®XXX" æ ¼å¼
                m = re.search(r"é¡¹ç›®([\u4e00-\u9fa5A-Za-z0-9_\-]+)", text)
                if m:
                    project_name = m.group(1)

        # æå–"æŸ¥è¯¢XXXçš„æŠ¥å·¥/XXXæŠ¥å·¥" => è®¤ä¸ºæ˜¯å‘˜å·¥å§“å
        print("ğŸ” å¼€å§‹è§£æå‘˜å·¥å§“å...")
        logger.info("ğŸ” å¼€å§‹è§£æå‘˜å·¥å§“å...")
        # ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ï¼šå…è®¸"æŸ¥è¯¢"å’Œ"æŠ¥å·¥"ä¹‹é—´æœ‰ç©ºæ ¼å’Œ"çš„"å­—
        m = re.search(r"æŸ¥è¯¢\s*([\u4e00-\u9fa5A-Za-z]{1,6})\s*çš„?\s*æŠ¥å·¥", text)
        if m:
            employee_name = m.group(1)
            print(f"  âœ… æ­£åˆ™åŒ¹é…æˆåŠŸ: '{employee_name}'")
            logger.info(f"  âœ… æ­£åˆ™åŒ¹é…æˆåŠŸ: '{employee_name}'")
            # å»é™¤å¯èƒ½çš„"çš„"å­—
            if employee_name.endswith('çš„'):
                employee_name = employee_name[:-1]
                print(f"  ğŸ”§ å»é™¤'çš„'å­—å: '{employee_name}'")
                logger.info(f"  ğŸ”§ å»é™¤'çš„'å­—å: '{employee_name}'")
        else:
            print("  âŒ æ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œæœªæ‰¾åˆ°å‘˜å·¥å")
            logger.info("  âŒ æ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œæœªæ‰¾åˆ°å‘˜å·¥å")
            # å°è¯•å…¶ä»–æ¨¡å¼
            print("  ğŸ” å°è¯•å…¶ä»–åŒ¹é…æ¨¡å¼...")
            logger.info("  ğŸ” å°è¯•å…¶ä»–åŒ¹é…æ¨¡å¼...")
            # å¯ä»¥æ·»åŠ æ›´å¤šåŒ¹é…æ¨¡å¼

        # æå–"è®¢å•/ç‰©æ–™/å·¥åº"å…³é”®è¯ï¼Œä½œä¸ºé€šç”¨keyword
        m = re.findall(r"(è®¢å•\S+|ç‰©æ–™\S+|å·¥åº\S+)", text)
        if m:
            keyword = " ".join(m)
        else:
            # å›é€€ï¼šå»é™¤åœç”¨è¯åçš„å‰©ä½™è¯ä½œä¸ºkeyword
            stop = ["æŸ¥è¯¢", "æŠ¥å·¥", "æƒ…å†µ", "çš„", "ä¸€ä¸‹", "ä¸‹", "è¯·", "å¸®æˆ‘", "é¡¹ç›®"]
            tmp = text
            for s in stop:
                tmp = tmp.replace(s, "")
            # ä¹Ÿè¦æ’é™¤å·²è¯†åˆ«çš„å‘˜å·¥åå’Œé¡¹ç›®åï¼ˆé¿å…keywordå’Œemployee_name/project_nameé‡å¤ï¼‰
            if employee_name:
                tmp = tmp.replace(employee_name, "")
            if project_name:
                tmp = tmp.replace(project_name, "")
            tmp = tmp.strip()
            if tmp:
                keyword = tmp

        # ä¸­æ–‡æ—¶é—´çŸ­è¯­è§£æï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼šä¸Šå‘¨/æœ¬å‘¨/ä¸Šæœˆ/æœ¬æœˆ/ä»Šå¹´/9æœˆ/2025-09
        def _first_day_of_this_month(today: date) -> date:
            return today.replace(day=1)

        def _first_day_of_last_month(today: date) -> date:
            first_this = _first_day_of_this_month(today)
            return (first_this - timedelta(days=1)).replace(day=1)

        def _last_day_of_month(some_day: date) -> date:
            next_month = (some_day.replace(day=28) + timedelta(days=4)).replace(day=1)
            return next_month - timedelta(days=1)

        today = date.today()
        lowered = text
        # ä¸Šå‘¨
        if re.search(r"ä¸Šå‘¨", lowered):
            weekday = today.weekday()  # 0=Mon
            last_sunday = today - timedelta(days=weekday + 1)
            last_monday = last_sunday - timedelta(days=6)
            start_date = last_monday
            end_date = last_sunday
        # æœ¬å‘¨
        elif re.search(r"æœ¬å‘¨|è¿™å‘¨", lowered):
            weekday = today.weekday()
            start_date = today - timedelta(days=weekday)
            end_date = start_date + timedelta(days=6)
        # ä¸Šæœˆ
        elif re.search(r"ä¸Šæœˆ|ä¸Šä¸ªæœˆ", lowered):
            first_last = _first_day_of_last_month(today)
            start_date = first_last
            end_date = _last_day_of_month(first_last)
        # æœ¬æœˆ
        elif re.search(r"æœ¬æœˆ|è¿™ä¸ªæœˆ", lowered):
            first_this = _first_day_of_this_month(today)
            start_date = first_this
            end_date = _last_day_of_month(first_this)
        # ä»Šå¹´
        elif re.search(r"ä»Šå¹´", lowered):
            start_date = date(today.year, 1, 1)
            end_date = date(today.year, 12, 31)
        else:
            # å½¢å¦‚ â€œ2025-09â€ æˆ– â€œ9æœˆ/09æœˆâ€
            m = re.search(r"(20\d{2})-(0?[1-9]|1[0-2])", lowered)
            if m:
                y = int(m.group(1)); mth = int(m.group(2))
                start_date = date(y, mth, 1)
                end_date = _last_day_of_month(start_date)
            else:
                m = re.search(r"(\d{1,2})æœˆ", lowered)
                if m:
                    mth = int(m.group(1))
                    y = today.year
                    start_date = date(y, mth, 1)
                    end_date = _last_day_of_month(start_date)

        # é»˜è®¤è¿‘90å¤©
        if not start_date and not end_date:
            end_date = today
            start_date = today - timedelta(days=90)
        
        # æ‰“å°è§£æç»“æœ
        logger.info("ğŸ“Š è§£æç»“æœ:")
        logger.info(f"  ğŸ‘¤ å‘˜å·¥å: '{employee_name}'")
        logger.info(f"  ğŸ¢ é¡¹ç›®å: '{project_name}'")
        logger.info(f"  ğŸ” å…³é”®è¯: '{keyword}'")
        logger.info(f"  ğŸ“… å¼€å§‹æ—¥æœŸ: '{start_date}'")
        logger.info(f"  ğŸ“… ç»“æŸæ—¥æœŸ: '{end_date}'")

        # è‹¥ç”¨æˆ·å¼€å¯LLMå¹¶é…ç½®äº†å¯†é’¥ï¼Œåˆ™ä¼˜å…ˆèµ°LLM function call
        use_llm = os.getenv("USE_LLM_WORKREPORT", "true").lower() == "true"
        openai_api_key = os.getenv("OPENAI_API_KEY", 'sk-c3ddf7d415bb492587f725ec3845a4ce')
        openai_base_url = os.getenv("OPENAI_BASE_URL", 'https://dashscope.aliyuncs.com/compatible-mode/v1')
        openai_model = os.getenv("WORKREPORT_LLM_MODEL", "qwen-max-latest")

        print(f"use_llm: {use_llm}")
        print(f"openai_api_key: {openai_api_key}")
        print(f"openai_base_url: {openai_base_url}")
        print(f"openai_model: {openai_model}")

        rows: List[Dict[str, Any]] = []
        explanation = None

        # ç›´æ¥ä½¿ç”¨SQLiteæ•°æ®åº“ï¼ˆä¸searchæ¥å£ä¿æŒä¸€è‡´ï¼‰
        from ...db.sqlite_db import get_sqlite_db
        db = get_sqlite_db()
        repo = WorkReportRepository(db)

        # æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢
        logger.info("ğŸ—„ï¸ å¼€å§‹æ•°æ®åº“æŸ¥è¯¢:")
        logger.info(f"  ğŸ“Š æŸ¥è¯¢å‚æ•°: employee_name='{employee_name}', project_name='{project_name}'")
        logger.info(f"  ğŸ“… æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
        logger.info(f"  ğŸ—ƒï¸ æ•°æ®åº“ç±»å‹: {type(db)}")
        logger.info(f"  ğŸ”— æ•°æ®åº“å®ä¾‹: {db}")
        
        # === å…ˆåˆ¤æ–­æ˜¯å¦æ›´åƒ"é—²èŠ/è¯´æ˜"è€Œé"æ•°æ®åº“æŸ¥è¯¢" ===
        # è§„åˆ™ï¼šæœªè¯†åˆ«åˆ°å®ä½“/æ—¶é—´/çŠ¶æ€ï¼Œä¸”å‘½ä¸­å¸¸è§é—²èŠè¯æˆ–å¥é•¿è¾ƒçŸ­
        def _is_smalltalk(q: str) -> bool:
            smalltalk_patterns = [
                r"^ä½ å¥½$", r"^åœ¨å—$", r"^å—¨$", r"^hello$", r"^hi$",
                r"å¸®åŠ©", r"è¯´æ˜", r"æ€ä¹ˆç”¨", r"ç¤ºä¾‹", r"åŠŸèƒ½",
            ]
            if any(re.search(p, q.strip(), re.IGNORECASE) for p in smalltalk_patterns):
                return True
            # æ— å®ä½“ä¸”å­—æ•°å¾ˆçŸ­ä¹Ÿè§†ä¸ºèŠå¤©
            no_entity = not any([employee_name, project_name]) and not any([start_date, end_date, status])
            return no_entity and len(q.strip()) <= 12

        if _is_smalltalk(text):
            explanation = None
            if openai_api_key and openai_base_url:
                try:
                    import requests
                    conv_system = (
                        "ä½ æ˜¯ä¼ä¸šæŠ¥å·¥åŠ©æ‰‹ã€‚ç”¨ç®€æ´ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®å€™æˆ–é—®é¢˜ï¼Œ"
                        "å¯æç¤ºä½¿ç”¨æ–¹å¼ä¸ç¤ºä¾‹é—®æ³•ï¼ˆå¦‚ï¼šæŸ¥è¯¢ç‹äº”9æœˆæŠ¥å·¥/AIæ™ºèƒ½åŠ©æ‰‹é¡¹ç›®ä¸Šå‘¨è®°å½•ï¼‰ï¼Œ"
                        "ä¸è¦ç¼–é€ å…·ä½“æ•°æ®æˆ–è¡¨æ ¼ã€‚"
                    )
                    resp_chat = requests.post(
                        f"{openai_base_url}/chat/completions",
                        headers={"Authorization": f"Bearer {openai_api_key}", "Content-Type": "application/json"},
                        json={
                            "model": openai_model,
                            "messages": [
                                {"role": "system", "content": conv_system},
                                {"role": "user", "content": text}
                            ]
                        }, timeout=30
                    )
                    resp_chat.raise_for_status()
                    data_chat = resp_chat.json()
                    explanation = (
                        data_chat.get("choices", [{}])[0]
                        .get("message", {})
                        .get("content")
                    )
                except Exception as _e:
                    logger.warning(f"LLMèŠå¤©å›ç­”å¤±è´¥: {_e}")
            # æ— LLMæˆ–å¤±è´¥ï¼Œç»™é»˜è®¤è¯´æ˜
            if not explanation:
                explanation = (
                    "ä½ å¥½ï¼Œæˆ‘æ˜¯æŠ¥å·¥æ™ºèƒ½ä½“ã€‚ä½ å¯ä»¥è¿™æ ·é—®æˆ‘ï¼š1) æŸ¥è¯¢ç‹äº”9æœˆæŠ¥å·¥ï¼›"
                    "2) AIæ™ºèƒ½åŠ©æ‰‹é¡¹ç›®ä¸Šå‘¨é€šè¿‡çš„è®°å½•ï¼›3) ç ”å‘éƒ¨æœ¬æœˆæŠ¥å·¥æ±‡æ€»ã€‚"
                )
            return {
                "success": True,
                "query": text,
                "parsed": {
                    "employee_name": None,
                    "project_name": None,
                    "keyword": None,
                    "start_date": None,
                    "end_date": None
                },
                "data": {"rows": [], "total": 0, "explanation": explanation}
            }

        if use_llm and openai_api_key and openai_base_url:
            try:
                # å°è¯•ä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼ˆfunction callï¼‰
                import requests
                system_prompt = (
                    "ä½ æ˜¯ä¸€ä¸ªä¼ä¸šçº§æŠ¥å·¥æ™ºèƒ½ä½“ï¼Œå°†ä¸­æ–‡é—®é¢˜è§£æä¸ºæŸ¥è¯¢å‚æ•°ï¼Œå¹¶ä¸¥æ ¼ä½¿ç”¨" \
                    "query_work_reports å‡½æ•°è¿›è¡Œæ£€ç´¢ï¼Œè¿”å›ç®€çŸ­ä¸­æ–‡è¯´æ˜ä¸è¡¨æ ¼è¡Œã€‚"
                )
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ]
                tools = [
                    {
                        "type": "function",
                        "function": {
                            "name": "query_work_reports",
                            "description": "æŸ¥è¯¢æŠ¥å·¥è®°å½•",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "employee_name": {"type": "string"},
                                    "project_name": {"type": "string"},
                                    "department_name": {"type": "string"},
                                    "status": {"type": "string", "enum": ["pending","approved","rejected"]},
                                    "start_date": {"type": "string"},
                                    "end_date": {"type": "string"},
                                    "size": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20}
                                },
                                "required": [],
                                "additionalProperties": False
                            }
                        }
                    }
                ]

                resp = requests.post(
                    f"{openai_base_url}/chat/completions",
                    headers={"Authorization": f"Bearer {openai_api_key}", "Content-Type": "application/json"},
                    json={
                        "model": openai_model,
                        "messages": messages,
                        "tools": tools,
                        "tool_choice": "auto"
                    }, timeout=30
                )
                resp.raise_for_status()
                data_json = resp.json()
                tool_calls = (
                    data_json.get("choices", [{}])[0]
                    .get("message", {})
                    .get("tool_calls", [])
                )
                # è‹¥æ¨¡å‹ç»™å‡ºå‡½æ•°è°ƒç”¨å‚æ•°ï¼Œåˆ™æ‰§è¡Œä»“å‚¨æŸ¥è¯¢
                args: Dict[str, Any] = {}
                if tool_calls:
                    for tc in tool_calls:
                        if tc.get("function", {}).get("name") == "query_work_reports":
                            import json as _json
                            arg_str = tc.get("function", {}).get("arguments", "{}")
                            try:
                                args = _json.loads(arg_str)
                            except Exception:
                                args = {}
                            break

                # åˆå¹¶è§„åˆ™è§£æå‡ºçš„æ—¶é—´çª—å£ä½œä¸ºç¼ºçœ
                if "start_date" not in args and start_date:
                    args["start_date"] = start_date.isoformat()
                if "end_date" not in args and end_date:
                    args["end_date"] = end_date.isoformat()
                size = int(args.get("size", payload.get("size", 20)))

                # è°ƒç”¨ä»“å‚¨
                def _coerce_date(s: Optional[str]) -> Optional[date]:
                    if not s:
                        return None
                    try:
                        return datetime.strptime(s, "%Y-%m-%d").date()
                    except Exception:
                        return None

                result = await repo.search_work_reports(
                    keyword=keyword,
                    employee_name=args.get("employee_name") or employee_name,
                    project_name=args.get("project_name") or project_name,
                    department_name=args.get("department_name"),
                    status=args.get("status"),
                    start_date=_coerce_date(args.get("start_date")) or start_date,
                    end_date=_coerce_date(args.get("end_date")) or end_date,
                    page=1,
                    size=size
                )
                rows = result.get("data", [])
                explanation = (
                    f"å·²ä¸ºä½ ç­›é€‰ï¼šå‘˜å·¥={args.get('employee_name') or (employee_name or 'æœªæŒ‡å®š')}ï¼Œ"
                    f"é¡¹ç›®={args.get('project_name') or (project_name or 'æœªæŒ‡å®š')}ï¼Œ"
                    f"æ—¶é—´={ ( (_coerce_date(args.get('start_date')) or start_date).isoformat() if (_coerce_date(args.get('start_date')) or start_date) else 'æœªæŒ‡å®š') }"
                    f"~{ ( (_coerce_date(args.get('end_date')) or end_date).isoformat() if (_coerce_date(args.get('end_date')) or end_date) else 'æœªæŒ‡å®š') }ï¼Œ"
                    f"å…±{result.get('total', len(rows))}æ¡ç»“æœã€‚"
                )
            except Exception as _e:
                logger.warning(f"LLMè°ƒç”¨å¤±è´¥ï¼Œå›é€€è§„åˆ™è§£æ: {_e}")
                result = await repo.search_work_reports(
                    keyword=keyword,
                    employee_name=employee_name,
                    project_name=project_name,
                    start_date=start_date,
                    end_date=end_date,
                    page=int(payload.get("page", 1)),
                    size=int(payload.get("size", 20))
                )
                rows = result.get("data", [])
        else:
            # ç›´æ¥è§„åˆ™è§£ææŸ¥è¯¢
            result = await repo.search_work_reports(
                keyword=keyword,
                employee_name=employee_name,
                project_name=project_name,
                start_date=start_date,
                end_date=end_date,
                page=int(payload.get("page", 1)),
                size=int(payload.get("size", 20))
            )
            rows = result.get("data", [])

        # æŸ¥è¯¢ç»“æœå¤„ç†
        logger.info(f"ğŸ“‹ æ•°æ®åº“æŸ¥è¯¢å®Œæˆ:")
        logger.info(f"  ğŸ“Š æŸ¥è¯¢åˆ°è®°å½•æ•°: {len(rows)}")
        logger.info(f"  ğŸ“ è®°å½•è¯¦æƒ…: {[{'id': r.get('id'), 'employee_name': r.get('employee_name'), 'report_date': r.get('report_date')} for r in rows[:3]]}")
        
        # è‹¥æ— å‘½ä¸­è®°å½•ï¼Œèµ°å¯¹è¯å¼å›ç­”å…œåº•ï¼ˆä¼˜å…ˆç”¨LLMï¼Œæ²¡æœ‰åˆ™ç»™å‡ºè§„åˆ™å»ºè®®æ–‡æ¡ˆï¼‰
        if not rows:
            logger.info("âš ï¸ æœªæŸ¥è¯¢åˆ°è®°å½•ï¼Œå‡†å¤‡ç”Ÿæˆè§£é‡Šè¯´æ˜")
            if openai_api_key and openai_base_url:
                try:
                    import requests
                    conv_system = (
                        "ä½ ç°åœ¨æ‰®æ¼”ä¼ä¸šæŠ¥å·¥åŠ©æ‰‹ã€‚å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°ç¬¦åˆæ¡ä»¶çš„æŠ¥å·¥æ•°æ®ï¼Œ"
                        "è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå‹å¥½çš„è¯´æ˜ã€å¯å°è¯•çš„æŸ¥è¯¢å»ºè®®ï¼ˆå¦‚è¡¥å……å‘˜å·¥/é¡¹ç›®/æ—¶é—´ï¼‰ï¼Œ"
                        "å¹¶æä¾›1-2æ¡å¯èƒ½æœ‰å¸®åŠ©çš„ç¤ºä¾‹é—®æ³•ã€‚ä¸è¦æé€ æ•°æ®è¡¨æ ¼ã€‚"
                    )
                    resp2 = requests.post(
                        f"{openai_base_url}/chat/completions",
                        headers={"Authorization": f"Bearer {openai_api_key}", "Content-Type": "application/json"},
                        json={
                            "model": openai_model,
                            "messages": [
                                {"role": "system", "content": conv_system},
                                {"role": "user", "content": text}
                            ]
                        }, timeout=30
                    )
                    resp2.raise_for_status()
                    data2 = resp2.json()
                    completion = (
                        data2.get("choices", [{}])[0]
                        .get("message", {})
                        .get("content")
                    )
                    if completion:
                        explanation = completion
                except Exception as _e:
                    logger.warning(f"LLMæ— æ•°æ®å¯¹è¯å…œåº•å¤±è´¥: {_e}")
            # è‹¥LLMä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œè¿”å›é»˜è®¤å»ºè®®è¯´æ˜
            if not explanation:
                explanation = (
                    "æœªæ£€ç´¢åˆ°ç›¸å…³æŠ¥å·¥è®°å½•ã€‚å»ºè®®ï¼š1) æŒ‡å®šå‘˜å·¥å§“åï¼ˆå¦‚ï¼šæŸ¥è¯¢ç‹äº”9æœˆæŠ¥å·¥ï¼‰ï¼›"
                    "2) æŒ‡å®šé¡¹ç›®åç§°ï¼ˆå¦‚ï¼šAIæ™ºèƒ½åŠ©æ‰‹é¡¹ç›®ä¸Šå‘¨è®°å½•ï¼‰ï¼›3) æŒ‡å®šæ—¶é—´èŒƒå›´ï¼ˆå¦‚ï¼š2025-09ã€ä¸Šå‘¨ã€æœ¬æœˆï¼‰ã€‚"
                )

        # è‹¥ç”¨æˆ·å¸Œæœ›â€œæ­£å¸¸æ²Ÿé€šä¹Ÿç”±å¤§æ¨¡å‹ä½œç­”â€ï¼Œåˆ™åœ¨è¿”å›å‰ä¼˜å…ˆç”¨LLMç”Ÿæˆç®€çŸ­è¯´æ˜
        if openai_api_key and openai_base_url and not explanation:
            try:
                import requests as _rq
                sys_prompt = (
                    "ä½ æ˜¯ä¼ä¸šæŠ¥å·¥åŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´ä¸­æ–‡ç¡®è®¤ä½ å¯¹ç”¨æˆ·é—®é¢˜çš„ç†è§£ï¼Œ"
                    "å¦‚æœå¯èƒ½ï¼Œç‚¹æ˜ä½ å°†ä¾æ®çš„ç­›é€‰æ¡ä»¶ï¼ˆå‘˜å·¥/é¡¹ç›®/æ—¶é—´/çŠ¶æ€ï¼‰ï¼Œ"
                    "å¹¶æç¤ºâ€˜ä¸‹æ–¹è¡¨æ ¼ä¸ºåŒ¹é…ç»“æœâ€™ã€‚ä¸è¦ç¼–é€ æ•°æ®ã€‚"
                )
                parsed_text = (
                    f"å‘˜å·¥={employee_name or 'æœªæŒ‡å®š'}ï¼Œé¡¹ç›®={project_name or 'æœªæŒ‡å®š'}ï¼Œ"
                    f"æ—¶é—´={ (start_date.isoformat() if start_date else 'æœªæŒ‡å®š') }~{ (end_date.isoformat() if end_date else 'æœªæŒ‡å®š') }ã€‚"
                )
                _resp = _rq.post(
                    f"{openai_base_url}/chat/completions",
                    headers={"Authorization": f"Bearer {openai_api_key}", "Content-Type": "application/json"},
                    json={
                        "model": openai_model,
                        "messages": [
                            {"role": "system", "content": sys_prompt},
                            {"role": "user", "content": f"åŸå§‹é—®é¢˜ï¼š{text}\nå·²è§£æï¼š{parsed_text}"}
                        ]
                    }, timeout=20
                )
                _resp.raise_for_status()
                _data = _resp.json()
                explanation = (
                    _data.get("choices", [{}])[0]
                    .get("message", {})
                    .get("content")
                ) or explanation
            except Exception as _e:
                logger.debug(f"LLMç®€è¦è¯´æ˜ç”Ÿæˆå¤±è´¥: {_e}")

        # æœ€ç»ˆå“åº”
        response_data = {
            "success": True,
            "query": text,
            "parsed": {
                "employee_name": employee_name,
                "project_name": project_name,
                "keyword": keyword,
                "start_date": start_date.isoformat() if start_date else None,
                "end_date": end_date.isoformat() if end_date else None
            },
            "data": {
                "rows": rows,
                "total": result.get("total", len(rows)),
                "explanation": explanation
            }
        }
        
        logger.info("âœ… å“åº”æ•°æ®å‡†å¤‡å®Œæˆ:")
        logger.info(f"  ğŸ“Š æˆåŠŸçŠ¶æ€: {response_data['success']}")
        logger.info(f"  ğŸ“ è§£æç»“æœ: {response_data['parsed']}")
        logger.info(f"  ğŸ“‹ æ•°æ®æ¡æ•°: {len(rows)}")
        logger.info(f"  ğŸ’¬ è§£é‡Šè¯´æ˜: {explanation[:100] if explanation else 'None'}...")
        logger.info("=" * 50)
        
        return response_data
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"AIæŸ¥è¯¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
